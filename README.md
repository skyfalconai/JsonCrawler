# ğŸ§  JSONCrawler â€“ Automated Data Extractor for Agents

The **JSONCrawler** is a lightweight Python utility designed to **automatically extract and format structured data (like JSON responses from APIs)** into **clean, human-readable strings** â€” ready to be used as **context for LLM prompts, agent system messages, or downstream processing**.

This is especially useful when integrating external APIs (e.g., weather, news, finance) into intelligent systems, where the raw JSON needs to be **summarized into a natural-language context** without manual parsing.

---

## ğŸš€ Features

* âœ… **Automatic traversal** of nested JSON objects and lists
* âœ… Extracts **keys and values recursively**
* âœ… Customizable output (limit items, choose keys, etc.)
* âœ… Returns **plain text strings**, perfect for LLM prompts or system messages
* âœ… Easily embeddable into agents, IoT projects.

---

## ğŸ“¦ Installation

Just drop the `JsonCrawler` class into your project â€” no external dependencies required.
or simply copy the class into your project file.

---

## ğŸ§° Usage Example

```python

crawler = JsonCrawler()

# Sample JSON from a weather API
data = {
    "location": "Ludhiana",
    "temperature": "31Â°C",
    "condition": "Cloudy",
    "forecast": [
        {"day": "Monday", "high": "33Â°C", "low": "25Â°C"},
        {"day": "Tuesday", "high": "32Â°C", "low": "24Â°C"}
    ]
}

result = crawler.process(data)
print(result)
```

This result can be directly appended to a system prompt for an LLM or used as context by an intelligent agent.

---

## âš™ï¸ API Reference

### `crawl_object(obj: dict, **kwargs) -> str`

Crawls a JSON/dict object and returns a flattened string.

| Parameter | Type                   | Description                     |
| --------- | ---------------------- | ------------------------------- |
| `obj`     | `dict`                 | JSON or dictionary to parse     |
| `extract` | `list[str]` (optional) | Keys to extract specifically    |
| `n_items` | `int` (optional)       | Limit number of items processed |

---

### `crawl_list(lst: list, **kwargs) -> str`

Iterates through a list of objects and concatenates their crawled strings.

| Parameter | Type             | Description                              |
| --------- | ---------------- | ---------------------------------------- |
| `lst`     | `list`           | List of JSON objects                     |
| `n_items` | `int` (optional) | Limit number of list elements to process |

---

## ğŸ§  Real-World Use Cases

* ğŸ¤– **Agent Systems** â€“ Convert structured API responses into natural language context.
* ğŸŒ¦ï¸ **Weather/News Assistants** â€“ Fetch live data and pass it directly into prompts.
* ğŸ›°ï¸ **Wearable Devices (e.g., Arc Reactor)** â€“ Automate sensor data parsing without custom logic.
* ğŸ“Š **Dashboards or Reports** â€“ Generate readable summaries from complex JSON payloads.

---

## ğŸ§ª Future Improvements

* ğŸ” Stream parsing for very large JSON payloads
* âš¡ Async support for API-heavy workflows
* ğŸ§¹ Intelligent key filtering and summarization
* ğŸ§  Integration with vector databases for semantic retrieval

---

## ğŸ“œ License

MIT License Â© 2025 â€“ Built for intelligent agents and real-time assistants.
